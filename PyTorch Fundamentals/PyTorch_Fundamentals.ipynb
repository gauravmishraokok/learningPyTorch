{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas\n",
    "    print(\"All modules imported!\")\n",
    "\n",
    "except:\n",
    "    print(\"Error in Importing :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors Introduction -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000)\n",
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "scalar=torch.tensor(1000)\n",
    "print(scalar)\n",
    "print(scalar.ndim)\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1000, 2000])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1000,2000])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor(5)\n",
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "print(MATRIX)\n",
    "print(MATRIX[1][1])\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 2,  4,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "3\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [2,4,6]\n",
    "    ],\n",
    "    [\n",
    "        [7,8,9],\n",
    "        [10,11,12]\n",
    "    ]\n",
    "])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Tensors -> Most NN start with RT and then update their values(by Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.8860, 0.5832, 0.3376, 0.8090, 0.5779],\n",
      "          [0.9040, 0.5547, 0.3423, 0.6343, 0.3644],\n",
      "          [0.7104, 0.9464, 0.7890, 0.2814, 0.7886],\n",
      "          [0.5895, 0.7539, 0.1952, 0.0050, 0.3068]],\n",
      "\n",
      "         [[0.1165, 0.9103, 0.6440, 0.7071, 0.6581],\n",
      "          [0.4913, 0.8913, 0.1447, 0.5315, 0.1587],\n",
      "          [0.6542, 0.3278, 0.6532, 0.3958, 0.9147],\n",
      "          [0.2036, 0.2018, 0.2018, 0.9497, 0.6666]],\n",
      "\n",
      "         [[0.9811, 0.0874, 0.0041, 0.1088, 0.1637],\n",
      "          [0.7025, 0.6790, 0.9155, 0.2418, 0.1591],\n",
      "          [0.7653, 0.2979, 0.8035, 0.3813, 0.7860],\n",
      "          [0.1115, 0.2477, 0.6524, 0.6057, 0.3725]]],\n",
      "\n",
      "\n",
      "        [[[0.7980, 0.8399, 0.1374, 0.2331, 0.9578],\n",
      "          [0.3313, 0.3227, 0.0162, 0.2137, 0.6249],\n",
      "          [0.4340, 0.1371, 0.5117, 0.1585, 0.0758],\n",
      "          [0.2247, 0.0624, 0.1816, 0.9998, 0.5944]],\n",
      "\n",
      "         [[0.6541, 0.0337, 0.1716, 0.3336, 0.5782],\n",
      "          [0.0600, 0.2846, 0.2007, 0.5014, 0.3139],\n",
      "          [0.4654, 0.1612, 0.1568, 0.2083, 0.3289],\n",
      "          [0.1054, 0.9192, 0.4008, 0.9302, 0.6558]],\n",
      "\n",
      "         [[0.0766, 0.8460, 0.3624, 0.3083, 0.0850],\n",
      "          [0.0029, 0.6431, 0.3908, 0.6947, 0.0897],\n",
      "          [0.8712, 0.1330, 0.4137, 0.6044, 0.7581],\n",
      "          [0.9037, 0.9555, 0.1035, 0.6258, 0.2849]]]])\n",
      "4\n",
      "torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "t2=torch.rand(2,3,4,5)\n",
    "print(t2)\n",
    "print(t2.ndim)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.4452076  0.6114744  0.76097107]\n",
      "  [0.12575495 0.22336179 0.7627566 ]\n",
      "  [0.9554293  0.24693054 0.6869636 ]\n",
      "  [0.13302475 0.47612214 0.4121393 ]]\n",
      "\n",
      " [[0.7672256  0.77918065 0.36759937]\n",
      "  [0.6757198  0.3722331  0.55349046]\n",
      "  [0.66247797 0.21471256 0.41167295]\n",
      "  [0.2296769  0.32877856 0.35099947]]\n",
      "\n",
      " [[0.95447576 0.12646258 0.81960344]\n",
      "  [0.6098752  0.67831624 0.9296998 ]\n",
      "  [0.56432    0.8870201  0.45050132]\n",
      "  [0.0593726  0.02927983 0.38805157]]\n",
      "\n",
      " [[0.70989424 0.61612535 0.50729614]\n",
      "  [0.4249897  0.7582959  0.47014588]\n",
      "  [0.27093786 0.5906647  0.62020564]\n",
      "  [0.9294733  0.32193768 0.6401168 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Random Image Tensor -> \n",
    "#256,256,3 -> H,W, Colour Channels -> RGB\n",
    "import torchvision\n",
    "t3=torch.rand(size=(3,4,4))\n",
    "t3=torchvision.utils.make_grid(t3)\n",
    "t3=t3.permute(1,2,0).numpy()\n",
    "plt.imshow(t3)\n",
    "plt.show()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#Tensor zeroes -> \n",
    "t4=torch.zeros(2,2)\n",
    "print(t4)\n",
    "\n",
    "#Tensor ones -> \n",
    "t5=torch.ones(3,3)\n",
    "print(t5)\n",
    "print(t5.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Range of Tensors  &  Torch like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([  0,  25,  50,  75, 100])\n",
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "t6=torch.arange(1,11)\n",
    "print(t6)\n",
    "t6=torch.arange(0,101,25)\n",
    "print(t6)\n",
    "\n",
    "t7=torch.zeros_like(t6)\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Some parameters for tensor creation\n",
    "t8 = torch.tensor([1,2,3],dtype=None,device=None,requires_grad=False)\n",
    "print(t8.device)\n",
    "t8 = torch.tensor([1,2,3],dtype=torch.float32,device=\"cuda\",requires_grad=False)\n",
    "print(t8.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "Shape of tensor: torch.Size([3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Getting information from Tensors -> \n",
    "\n",
    "print(t8)\n",
    "print(f\"Shape of tensor: {t8.shape}\")\n",
    "print(f\"Datatype of tensor: {t8.dtype}\")\n",
    "print(f\"Device tensor is stored on: {t8.device}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations -> \n",
    "* Addition \n",
    "* Subtraction\n",
    "* Multiplication ( Element-wise )\n",
    "* Division \n",
    "* Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "tensor([[0.0459, 0.3155, 0.9211],\n",
      "        [0.6948, 0.4751, 0.1985],\n",
      "        [0.1941, 0.0521, 0.3370]]) \n",
      "\n",
      "tensor([[1.0459, 1.3155, 1.9211],\n",
      "        [1.6948, 1.4751, 1.1985],\n",
      "        [1.1941, 1.0521, 1.3370]]) \n",
      "\n",
      "tensor([[0.9541, 0.6845, 0.0789],\n",
      "        [0.3052, 0.5249, 0.8015],\n",
      "        [0.8059, 0.9479, 0.6630]]) \n",
      "\n",
      "tensor([[0.0459, 0.3155, 0.9211],\n",
      "        [0.6948, 0.4751, 0.1985],\n",
      "        [0.1941, 0.0521, 0.3370]]) \n",
      "\n",
      "tensor([[21.8000,  3.1698,  1.0857],\n",
      "        [ 1.4393,  2.1047,  5.0366],\n",
      "        [ 5.1521, 19.1878,  2.9672]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1=torch.ones(3,3)\n",
    "print(t1,\"\\n\")\n",
    "t2=torch.rand(3,3)\n",
    "print(t2,\"\\n\")\n",
    "print(t1+t2,\"\\n\")\n",
    "print(t1-t2,\"\\n\")\n",
    "print(t1*t2,\"\\n\")\n",
    "print(t1/t2,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11., 11.],\n",
       "        [11., 11., 11.],\n",
       "        [11., 11., 11.]])"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(55)\n"
     ]
    }
   ],
   "source": [
    "#Matrix Multiplication -> \n",
    "t1=torch.tensor([1,2,3,4,5])\n",
    "t2=torch.matmul(t1,t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[55, 56],\n",
      "        [56, 58]])\n"
     ]
    }
   ],
   "source": [
    "#Most common error in Deep Learning -> Shape Errors\n",
    "\n",
    "\n",
    "t1=torch.tensor([[1,2,3,4,5],[2,2,3,4,5]])\n",
    "t2=torch.matmul(t1,t1.T)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tensor Aggregation -> \n",
    "- Min \n",
    "- Max\n",
    "- Mean\n",
    "- Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([100., 110., 120., 130., 140., 150., 160., 170., 180., 190., 200.])\n",
      "tensor(100.)\n",
      "tensor(0)\n",
      "tensor(10)\n",
      "tensor(200.)\n",
      "tensor(150.)\n",
      "tensor(1650.)\n"
     ]
    }
   ],
   "source": [
    "t1=torch.arange(100.,201,10)\n",
    "print(t1)\n",
    "print(t1.min())\n",
    "print(t1.argmin())\n",
    "print(t1.argmax())\n",
    "print(t1.max())\n",
    "print(t1.mean())\n",
    "print(t1.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Reshaping, Stacking, Squeezing and Unsqueezing\n",
    "- Reshape -> Change of Shape\n",
    "- View -> Returns a view of a tensor without changing it\n",
    "- Stacking -> Combine multiple tensors either vertically(*vstack*) or horizontally(*hstack*)\n",
    "- Squeezing -> Removes all `1` dimensions from the tensor\n",
    "- Unsqueezing -> Adds a `1` dimension to the tensor\n",
    "- Permute -> Returns view of a tensor's view permuted(*swapped*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "tensor([[ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12]])\n"
     ]
    }
   ],
   "source": [
    "#Reshaping\n",
    "t1=torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(t1.size())\n",
    "print(t1.reshape(1,12))\n",
    "print(t1.reshape(2,6))\n",
    "print(t1.reshape(3,4))\n",
    "print(t1.reshape(4,3))\n",
    "print(t1.reshape(6,2))\n",
    "print(t1.reshape(12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "\n",
      "\n",
      "tensor([[11, 12, 13],\n",
      "        [14, 15, 16],\n",
      "        [17, 18, 19],\n",
      "        [20, 21, 22]])\n",
      "tensor([[11, 12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 20, 21, 22]])\n"
     ]
    }
   ],
   "source": [
    "#Viewing\n",
    "t2=t1.view(2,6)\n",
    "print(t1)\n",
    "print(t2)\n",
    "t2+=10\n",
    "print(\"\\n\")\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5]) \n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5]]) \n",
      "\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4],\n",
      "        [5, 5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "#Stacking\n",
    "t1=torch.arange(1,6)\n",
    "print(t1,\"\\n\")\n",
    "t2=torch.stack([t1,t1,t1,t1],dim=0) #vstack\n",
    "print(t2,\"\\n\")\n",
    "t2=torch.stack([t1,t1,t1,t1],dim=1) #hstack\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6542, 0.3278, 0.6532, 0.3958, 0.9147]]])\n",
      "torch.Size([1, 1, 5]) \n",
      "\n",
      "tensor([0.6542, 0.3278, 0.6532, 0.3958, 0.9147])\n",
      "torch.Size([5]) \n",
      "\n",
      "\n",
      "tensor([[0.6542, 0.3278, 0.6532, 0.3958, 0.9147]])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "#Squeeze, Unsqueeze\n",
    "t3=torch.rand(1,1,5)\n",
    "print(t3)\n",
    "print(t3.size(),\"\\n\")\n",
    "t3=torch.squeeze(t3)\n",
    "print(t3)\n",
    "print(t3.size(),\"\\n\\n\")\n",
    "\n",
    "t3=torch.unsqueeze(t3,dim=0)\n",
    "print(t3)\n",
    "print(t3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) \n",
      "\n",
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#Permute\n",
    "t1=torch.randn(2,3,4)\n",
    "print(t1.size(),\"\\n\")\n",
    "\n",
    "t2=torch.permute(t1,(2,0,1))\n",
    "print(t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "          [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
      "          [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]],\n",
      "\n",
      "         [[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "          [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
      "          [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]],\n",
      "\n",
      "         [[67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77],\n",
      "          [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88],\n",
      "          [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]]]) \n",
      "\n",
      "\n",
      "tensor(63)\n",
      "\n",
      "\n",
      "tensor([[[ 1, 12, 23],\n",
      "         [34, 45, 56],\n",
      "         [67, 78, 89]]])\n"
     ]
    }
   ],
   "source": [
    "#Indexing -> Exactly same as python or numpy.\n",
    "t1=torch.arange(1,100).reshape(1,3,3,11)\n",
    "print(t1,\"\\n\\n\")\n",
    "#Printing 63 for example: \n",
    "print(t1[0][1][-1][-4])\n",
    "print(\"\\n\")\n",
    "print(t1[:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch and Numpy -> \n",
    "- Data in NumPy to PyTorch Tensor -> torch.from_numpy(ndarray)\n",
    "- PyTorch Tensor to Data in Numpy -> torch.tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NumPy to Tensor\n",
    "numpyArr=np.arange(1.,10)\n",
    "convertedTensor = torch.from_numpy(numpyArr)\n",
    "numpyArr,convertedTensor\n",
    "#When converting from numpy, The datatype is default NumPy datatype,\n",
    "#i.e. float64. Thus some type conversion might be needed here.\n",
    "\n",
    "#Changes brought to numpyArr wouldnt be reflected in convertedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " array([[1., 1.],\n",
       "        [1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor to NumPy \n",
    "ogTensor = torch.ones(2,2)\n",
    "convertedArr=ogTensor.numpy()\n",
    "ogTensor,convertedArr\n",
    "#Same datatype conversion concept here too.\n",
    "#Same change to original concept here too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Reproducibility -> \n",
    "* Taking the random out of the random\n",
    "\n",
    "` NN learn by taking initial random numbers -> Operations -> Updation -> O | U iteratively`\n",
    "The concept of ****Random Seed**** comes to \"reduce\" the randomness.\n",
    "\n",
    "This when used at different places where random is being used gives the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4636, 0.4828, 0.1103, 0.8470],\n",
      "        [0.1160, 0.9668, 0.1558, 0.4315],\n",
      "        [0.5935, 0.2778, 0.9598, 0.1553]])\n",
      "tensor([[0.4723, 0.1329, 0.6388, 0.9263],\n",
      "        [0.9638, 0.5594, 0.2497, 0.9859],\n",
      "        [0.5373, 0.8383, 0.2403, 0.2680]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.rand(3,4)\n",
    "t2=torch.rand(3,4)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t1==t2)\n",
    "#Random around 150 times, Never got true in even 1 entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      " tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#Setting up Manual Seed\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t1=torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t2=torch.rand(3,4)\n",
    "print(t1,\"\\n\",t2,\"\\n\",t1==t2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Tensors and PyTorch objects on GPU →\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 26 18:47:52 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   57C    P8              4W /   90W |     967MiB /   4096MiB |     10%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1008    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      2528    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A      3780    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A      5776    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10448    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10476    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10484    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11640    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     13464    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13800    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16016    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A     24180    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     24592      C   ...rograms\\Python\\Python312\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     25784    C+G   ...m\\radeonsoftware\\RadeonSoftware.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting our Tensors and Models on GPU -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "t1=torch.randn(3,3)\n",
    "print(t1.device)\n",
    "\n",
    "t2=t1.to(device)\n",
    "print(t2.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Classic error -> \n",
    "#If a tensor is on GPU we can't do NumPy transformation.\n",
    "\n",
    "#Moving tensors back to CPU -> \n",
    "t3=t2.cpu()\n",
    "print(t3.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of PyTorch Fundamentals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
