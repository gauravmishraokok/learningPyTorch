{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch Fundamentals -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All modules imported!\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    import torch\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import pandas\n",
    "    print(\"All modules imported!\")\n",
    "\n",
    "except:\n",
    "    print(\"Error in Importing :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensors Introduction -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1000)\n",
      "0\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "scalar=torch.tensor(1000)\n",
    "print(scalar)\n",
    "print(scalar.ndim)\n",
    "print(scalar.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1000, 2000])\n",
      "1\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "vector = torch.tensor([1000,2000])\n",
    "print(vector)\n",
    "print(vector.ndim)\n",
    "print(vector.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2, 3],\n",
      "        [4, 5, 6],\n",
      "        [7, 8, 9]])\n",
      "tensor(5)\n",
      "2\n",
      "torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "MATRIX = torch.tensor([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "print(MATRIX)\n",
    "print(MATRIX[1][1])\n",
    "print(MATRIX.ndim)\n",
    "print(MATRIX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1,  2,  3],\n",
      "         [ 2,  4,  6]],\n",
      "\n",
      "        [[ 7,  8,  9],\n",
      "         [10, 11, 12]]])\n",
      "3\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "TENSOR = torch.tensor([\n",
    "    [\n",
    "        [1,2,3],\n",
    "        [2,4,6]\n",
    "    ],\n",
    "    [\n",
    "        [7,8,9],\n",
    "        [10,11,12]\n",
    "    ]\n",
    "])\n",
    "print(TENSOR)\n",
    "print(TENSOR.ndim)\n",
    "print(TENSOR.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Tensors -> Most NN start with RT and then update their values(by Learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0.4737, 0.8748, 0.9354, 0.8568, 0.6768],\n",
      "          [0.8128, 0.2678, 0.6984, 0.1247, 0.9350],\n",
      "          [0.7807, 0.3678, 0.6605, 0.3574, 0.5379],\n",
      "          [0.8614, 0.4428, 0.2454, 0.1243, 0.9648]],\n",
      "\n",
      "         [[0.6029, 0.7116, 0.1096, 0.2806, 0.1820],\n",
      "          [0.4426, 0.3570, 0.7796, 0.8094, 0.1512],\n",
      "          [0.4941, 0.3590, 0.9176, 0.6668, 0.7477],\n",
      "          [0.8526, 0.3325, 0.9638, 0.1258, 0.1260]],\n",
      "\n",
      "         [[0.4273, 0.4287, 0.0385, 0.6241, 0.5887],\n",
      "          [0.3181, 0.6030, 0.1607, 0.3911, 0.3640],\n",
      "          [0.1356, 0.1684, 0.2114, 0.0589, 0.3678],\n",
      "          [0.7806, 0.8669, 0.1609, 0.4902, 0.3434]]],\n",
      "\n",
      "\n",
      "        [[[0.8266, 0.2857, 0.5882, 0.6328, 0.4350],\n",
      "          [0.5436, 0.7131, 0.1004, 0.9051, 0.7628],\n",
      "          [0.7128, 0.8881, 0.5045, 0.6988, 0.8534],\n",
      "          [0.4476, 0.6820, 0.8915, 0.8904, 0.2367]],\n",
      "\n",
      "         [[0.2032, 0.5498, 0.6267, 0.6447, 0.2315],\n",
      "          [0.7675, 0.8979, 0.1545, 0.8518, 0.0110],\n",
      "          [0.7755, 0.9713, 0.0644, 0.1328, 0.7850],\n",
      "          [0.1101, 0.6237, 0.5937, 0.7605, 0.6611]],\n",
      "\n",
      "         [[0.1720, 0.0747, 0.8633, 0.2480, 0.8881],\n",
      "          [0.3069, 0.7251, 0.3055, 0.9114, 0.7649],\n",
      "          [0.1033, 0.7380, 0.1731, 0.1881, 0.2264],\n",
      "          [0.1710, 0.9813, 0.8709, 0.6508, 0.6441]]]])\n",
      "4\n",
      "torch.Size([2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "t2=torch.rand(2,3,4,5)\n",
    "print(t2)\n",
    "print(t2.ndim)\n",
    "print(t2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visual Representation of torch.rand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0.8860137  0.7539175  0.65320814]\n",
      "  [0.5832096  0.19524747 0.39582926]\n",
      "  [0.33764774 0.00504577 0.9146959 ]\n",
      "  [0.808975   0.30681974 0.20364904]]\n",
      "\n",
      " [[0.5779254  0.11648858 0.201801  ]\n",
      "  [0.9039817  0.91026944 0.201783  ]\n",
      "  [0.55465984 0.64401567 0.9497214 ]\n",
      "  [0.3423134  0.70710677 0.66662556]]\n",
      "\n",
      " [[0.63434184 0.6581306  0.98112535]\n",
      "  [0.36441028 0.491302   0.08736187]\n",
      "  [0.7104288  0.89130414 0.00406194]\n",
      "  [0.9464111  0.1447432  0.10881811]]\n",
      "\n",
      " [[0.7890298  0.53148186 0.16365546]\n",
      "  [0.28141373 0.15872991 0.7025201 ]\n",
      "  [0.78863233 0.654176   0.6790379 ]\n",
      "  [0.5894631  0.32780886 0.9154622 ]]]\n"
     ]
    }
   ],
   "source": [
    "#Random Image Tensor -> \n",
    "#256,256,3 -> H,W, Colour Channels -> RGB\n",
    "import torchvision\n",
    "t3=torch.rand(size=(3,4,4))\n",
    "t3=torchvision.utils.make_grid(t3)\n",
    "t3=t3.permute(1,2,0).numpy()\n",
    "plt.imshow(t3)\n",
    "plt.show()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0.],\n",
      "        [0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "#Tensor zeroes -> \n",
    "t4=torch.zeros(2,2)\n",
    "print(t4)\n",
    "\n",
    "#Tensor ones -> \n",
    "t5=torch.ones(3,3)\n",
    "print(t5)\n",
    "print(t5.dtype)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Range of Tensors  &  Torch like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10])\n",
      "tensor([  0,  25,  50,  75, 100])\n",
      "tensor([0, 0, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "t6=torch.arange(1,11)\n",
    "print(t6)\n",
    "t6=torch.arange(0,101,25)\n",
    "print(t6)\n",
    "\n",
    "t7=torch.zeros_like(t6)\n",
    "print(t7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Some parameters for tensor creation\n",
    "t8 = torch.tensor([1,2,3],dtype=None,device=None,requires_grad=False)\n",
    "print(t8.device)\n",
    "t8 = torch.tensor([1,2,3],dtype=torch.float32,device=\"cuda\",requires_grad=False)\n",
    "print(t8.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Information Extraction from Tensor Datatype ->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.], device='cuda:0')\n",
      "Shape of tensor: torch.Size([3])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cuda:0\n"
     ]
    }
   ],
   "source": [
    "#Getting information from Tensors -> \n",
    "\n",
    "print(t8)\n",
    "print(f\"Shape of tensor: {t8.shape}\")\n",
    "print(f\"Datatype of tensor: {t8.dtype}\")\n",
    "print(f\"Device tensor is stored on: {t8.device}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensor Operations -> \n",
    "* Addition \n",
    "* Subtraction\n",
    "* Multiplication ( Element-wise )\n",
    "* Division \n",
    "* Matrix Multiplication\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "tensor([[0.8792, 0.6483, 0.3386],\n",
      "        [0.4280, 0.6770, 0.4806],\n",
      "        [0.1694, 0.6212, 0.9727]]) \n",
      "\n",
      "tensor([[1.8792, 1.6483, 1.3386],\n",
      "        [1.4280, 1.6770, 1.4806],\n",
      "        [1.1694, 1.6212, 1.9727]]) \n",
      "\n",
      "tensor([[0.1208, 0.3517, 0.6614],\n",
      "        [0.5720, 0.3230, 0.5194],\n",
      "        [0.8306, 0.3788, 0.0273]]) \n",
      "\n",
      "tensor([[0.8792, 0.6483, 0.3386],\n",
      "        [0.4280, 0.6770, 0.4806],\n",
      "        [0.1694, 0.6212, 0.9727]]) \n",
      "\n",
      "tensor([[1.1374, 1.5424, 2.9530],\n",
      "        [2.3363, 1.4771, 2.0805],\n",
      "        [5.9018, 1.6098, 1.0281]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "t1=torch.ones(3,3)\n",
    "print(t1,\"\\n\")\n",
    "t2=torch.rand(3,3)\n",
    "print(t2,\"\\n\")\n",
    "print(t1+t2,\"\\n\")\n",
    "print(t1-t2,\"\\n\")\n",
    "print(t1*t2,\"\\n\")\n",
    "print(t1/t2,\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 11., 11.],\n",
       "        [11., 11., 11.],\n",
       "        [11., 11., 11.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1+10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(55)\n"
     ]
    }
   ],
   "source": [
    "#Matrix Multiplication -> \n",
    "t1=torch.tensor([1,2,3,4,5])\n",
    "t2=torch.matmul(t1,t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[55, 56],\n",
      "        [56, 58]])\n"
     ]
    }
   ],
   "source": [
    "#Most common error in Deep Learning -> Shape Errors\n",
    "\n",
    "\n",
    "t1=torch.tensor([[1,2,3,4,5],[2,2,3,4,5]])\n",
    "t2=torch.matmul(t1,t1.T)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensor Aggregation -> \n",
    "- Min \n",
    "- Max\n",
    "- Mean\n",
    "- Sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([100., 110., 120., 130., 140., 150., 160., 170., 180., 190., 200.])\n",
      "tensor(100.)\n",
      "tensor(0)\n",
      "tensor(10)\n",
      "tensor(200.)\n",
      "tensor(150.)\n",
      "tensor(1650.)\n"
     ]
    }
   ],
   "source": [
    "t1=torch.arange(100.,201,10)\n",
    "print(t1)\n",
    "print(t1.min())\n",
    "print(t1.argmin())\n",
    "print(t1.argmax())\n",
    "print(t1.max())\n",
    "print(t1.mean())\n",
    "print(t1.sum())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reshaping, Stacking, Squeezing and Unsqueezing\n",
    "- Reshape -> Change of Shape\n",
    "- View -> Returns a view of a tensor without changing it\n",
    "- Stacking -> Combine multiple tensors either vertically(*vstack*) or horizontally(*hstack*)\n",
    "- Squeezing -> Removes all `1` dimensions from the tensor\n",
    "- Unsqueezing -> Adds a `1` dimension to the tensor\n",
    "- Permute -> Returns view of a tensor's view permuted(*swapped*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "tensor([[ 1,  2,  3,  4],\n",
      "        [ 5,  6,  7,  8],\n",
      "        [ 9, 10, 11, 12]])\n",
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "tensor([[ 1,  2],\n",
      "        [ 3,  4],\n",
      "        [ 5,  6],\n",
      "        [ 7,  8],\n",
      "        [ 9, 10],\n",
      "        [11, 12]])\n",
      "tensor([[ 1],\n",
      "        [ 2],\n",
      "        [ 3],\n",
      "        [ 4],\n",
      "        [ 5],\n",
      "        [ 6],\n",
      "        [ 7],\n",
      "        [ 8],\n",
      "        [ 9],\n",
      "        [10],\n",
      "        [11],\n",
      "        [12]])\n"
     ]
    }
   ],
   "source": [
    "#Reshaping\n",
    "t1=torch.tensor([[1,2,3],[4,5,6],[7,8,9],[10,11,12]])\n",
    "print(t1.size())\n",
    "print(t1.reshape(1,12))\n",
    "print(t1.reshape(2,6))\n",
    "print(t1.reshape(3,4))\n",
    "print(t1.reshape(4,3))\n",
    "print(t1.reshape(6,2))\n",
    "print(t1.reshape(12,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1,  2,  3],\n",
      "        [ 4,  5,  6],\n",
      "        [ 7,  8,  9],\n",
      "        [10, 11, 12]])\n",
      "tensor([[ 1,  2,  3,  4,  5,  6],\n",
      "        [ 7,  8,  9, 10, 11, 12]])\n",
      "\n",
      "\n",
      "tensor([[11, 12, 13],\n",
      "        [14, 15, 16],\n",
      "        [17, 18, 19],\n",
      "        [20, 21, 22]])\n",
      "tensor([[11, 12, 13, 14, 15, 16],\n",
      "        [17, 18, 19, 20, 21, 22]])\n"
     ]
    }
   ],
   "source": [
    "#Viewing\n",
    "t2=t1.view(2,6)\n",
    "print(t1)\n",
    "print(t2)\n",
    "t2+=10\n",
    "print(\"\\n\")\n",
    "print(t1)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3, 4, 5]) \n",
      "\n",
      "tensor([[1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5],\n",
      "        [1, 2, 3, 4, 5]]) \n",
      "\n",
      "tensor([[1, 1, 1, 1],\n",
      "        [2, 2, 2, 2],\n",
      "        [3, 3, 3, 3],\n",
      "        [4, 4, 4, 4],\n",
      "        [5, 5, 5, 5]])\n"
     ]
    }
   ],
   "source": [
    "#Stacking\n",
    "t1=torch.arange(1,6)\n",
    "print(t1,\"\\n\")\n",
    "t2=torch.stack([t1,t1,t1,t1],dim=0) #vstack\n",
    "print(t2,\"\\n\")\n",
    "t2=torch.stack([t1,t1,t1,t1],dim=1) #hstack\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.0245, 0.0341, 0.1060, 0.9849, 0.0937]]])\n",
      "torch.Size([1, 1, 5]) \n",
      "\n",
      "tensor([0.0245, 0.0341, 0.1060, 0.9849, 0.0937])\n",
      "torch.Size([5]) \n",
      "\n",
      "\n",
      "tensor([[0.0245, 0.0341, 0.1060, 0.9849, 0.0937]])\n",
      "torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "#Squeeze, Unsqueeze\n",
    "t3=torch.rand(1,1,5)\n",
    "print(t3)\n",
    "print(t3.size(),\"\\n\")\n",
    "t3=torch.squeeze(t3)\n",
    "print(t3)\n",
    "print(t3.size(),\"\\n\\n\")\n",
    "\n",
    "t3=torch.unsqueeze(t3,dim=0)\n",
    "print(t3)\n",
    "print(t3.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4]) \n",
      "\n",
      "torch.Size([4, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "#Permute\n",
    "t1=torch.randn(2,3,4)\n",
    "print(t1.size(),\"\\n\")\n",
    "\n",
    "t2=torch.permute(t1,(2,0,1))\n",
    "print(t2.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11],\n",
      "          [12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22],\n",
      "          [23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33]],\n",
      "\n",
      "         [[34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44],\n",
      "          [45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55],\n",
      "          [56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66]],\n",
      "\n",
      "         [[67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77],\n",
      "          [78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88],\n",
      "          [89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99]]]]) \n",
      "\n",
      "\n",
      "tensor(63)\n",
      "\n",
      "\n",
      "tensor([[[ 1, 12, 23],\n",
      "         [34, 45, 56],\n",
      "         [67, 78, 89]]])\n"
     ]
    }
   ],
   "source": [
    "#Indexing -> Exactly same as python or numpy.\n",
    "t1=torch.arange(1,100).reshape(1,3,3,11)\n",
    "print(t1,\"\\n\\n\")\n",
    "#Printing 63 for example: \n",
    "print(t1[0][1][-1][-4])\n",
    "print(\"\\n\")\n",
    "print(t1[:,:,:,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch and Numpy -> \n",
    "- Data in NumPy to PyTorch Tensor -> torch.from_numpy(ndarray)\n",
    "- PyTorch Tensor to Data in Numpy -> torch.tensor.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([1., 2., 3., 4., 5., 6., 7., 8., 9.]),\n",
       " tensor([1., 2., 3., 4., 5., 6., 7., 8., 9.], dtype=torch.float64))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NumPy to Tensor\n",
    "numpyArr=np.arange(1.,10)\n",
    "convertedTensor = torch.from_numpy(numpyArr)\n",
    "numpyArr,convertedTensor\n",
    "#When converting from numpy, The datatype is default NumPy datatype,\n",
    "#i.e. float64. Thus some type conversion might be needed here.\n",
    "\n",
    "#Changes brought to numpyArr wouldnt be reflected in convertedTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 1.],\n",
       "         [1., 1.]]),\n",
       " array([[1., 1.],\n",
       "        [1., 1.]], dtype=float32))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tensor to NumPy \n",
    "ogTensor = torch.ones(2,2)\n",
    "convertedArr=ogTensor.numpy()\n",
    "ogTensor,convertedArr\n",
    "#Same datatype conversion concept here too.\n",
    "#Same change to original concept here too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PyTorch Reproducibility -> \n",
    "* Taking the random out of the random\n",
    "\n",
    "` NN learn by taking initial random numbers -> Operations -> Updation -> O | U iteratively`\n",
    "The concept of ****Random Seed**** comes to \"reduce\" the randomness.\n",
    "\n",
    "This when used at different places where random is being used gives the same results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2709, 0.3166, 0.3861, 0.7869],\n",
      "        [0.8560, 0.4529, 0.4841, 0.6163],\n",
      "        [0.5187, 0.9874, 0.0980, 0.0720]])\n",
      "tensor([[0.4257, 0.4177, 0.7336, 0.4794],\n",
      "        [0.1044, 0.0723, 0.2838, 0.0487],\n",
      "        [0.2118, 0.3031, 0.7764, 0.6283]])\n",
      "tensor([[False, False, False, False],\n",
      "        [False, False, False, False],\n",
      "        [False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "t1=torch.rand(3,4)\n",
    "t2=torch.rand(3,4)\n",
    "print(t1)\n",
    "print(t2)\n",
    "print(t1==t2)\n",
    "#Random around 150 times, Never got true in even 1 entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      " tensor([[0.8823, 0.9150, 0.3829, 0.9593],\n",
      "        [0.3904, 0.6009, 0.2566, 0.7936],\n",
      "        [0.9408, 0.1332, 0.9346, 0.5936]]) \n",
      " tensor([[True, True, True, True],\n",
      "        [True, True, True, True],\n",
      "        [True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "#Setting up Manual Seed\n",
    "RANDOM_SEED=42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t1=torch.rand(3,4)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "t2=torch.rand(3,4)\n",
    "print(t1,\"\\n\",t2,\"\\n\",t1==t2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Running Tensors and PyTorch objects on GPU →\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Aug 26 19:00:35 2024       \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 551.61                 Driver Version: 551.61         CUDA Version: 12.4     |\n",
      "|-----------------------------------------+------------------------+----------------------+\n",
      "| GPU  Name                     TCC/WDDM  | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                        |               MIG M. |\n",
      "|=========================================+========================+======================|\n",
      "|   0  NVIDIA GeForce RTX 3050 ...  WDDM  |   00000000:01:00.0  On |                  N/A |\n",
      "| N/A   59C    P3              8W /   82W |     998MiB /   4096MiB |     16%      Default |\n",
      "|                                         |                        |                  N/A |\n",
      "+-----------------------------------------+------------------------+----------------------+\n",
      "                                                                                         \n",
      "+-----------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                              |\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
      "|        ID   ID                                                               Usage      |\n",
      "|=========================================================================================|\n",
      "|    0   N/A  N/A      1008    C+G   ...siveControlPanel\\SystemSettings.exe      N/A      |\n",
      "|    0   N/A  N/A      3780    C+G   ...Brave-Browser\\Application\\brave.exe      N/A      |\n",
      "|    0   N/A  N/A      5776    C+G   C:\\Windows\\explorer.exe                     N/A      |\n",
      "|    0   N/A  N/A     10448    C+G   ...nt.CBS_cw5n1h2txyewy\\SearchHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10476    C+G   ...CBS_cw5n1h2txyewy\\TextInputHost.exe      N/A      |\n",
      "|    0   N/A  N/A     10484    C+G   ...2txyewy\\StartMenuExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     11640    C+G   ...n\\127.0.2651.105\\msedgewebview2.exe      N/A      |\n",
      "|    0   N/A  N/A     13464    C+G   ...t.LockApp_cw5n1h2txyewy\\LockApp.exe      N/A      |\n",
      "|    0   N/A  N/A     13800    C+G   ...5n1h2txyewy\\ShellExperienceHost.exe      N/A      |\n",
      "|    0   N/A  N/A     16016    C+G   ...ta\\Local\\Programs\\Notion\\Notion.exe      N/A      |\n",
      "|    0   N/A  N/A     17984      C   ...rograms\\Python\\Python312\\python.exe      N/A      |\n",
      "|    0   N/A  N/A     22036    C+G   ...Programs\\Microsoft VS Code\\Code.exe      N/A      |\n",
      "|    0   N/A  N/A     24180    C+G   ...US\\ArmouryDevice\\asus_framework.exe      N/A      |\n",
      "|    0   N/A  N/A     25784    C+G   ...m\\radeonsoftware\\RadeonSoftware.exe      N/A      |\n",
      "+-----------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Putting our Tensors and Models on GPU -> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "t1=torch.randn(3,3)\n",
    "print(t1.device)\n",
    "\n",
    "t2=t1.to(device)\n",
    "print(t2.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "#Classic error -> \n",
    "#If a tensor is on GPU we can't do NumPy transformation.\n",
    "\n",
    "#Moving tensors back to CPU -> \n",
    "t3=t2.cpu()\n",
    "print(t3.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### End of PyTorch Fundamentals."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
