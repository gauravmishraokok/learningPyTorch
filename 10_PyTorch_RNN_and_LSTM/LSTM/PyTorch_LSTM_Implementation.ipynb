{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LSTM -> Long Short Term Memory**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: center;\">\n",
    "    <img src=\"https://media.licdn.com/dms/image/v2/D4D22AQFr-MfhWK4pHw/feedshare-shrink_2048_1536/feedshare-shrink_2048_1536/0/1680639962661?e=1730332800&v=beta&t=rQ-tHL8kvSN9CLRb4TewSYYSsieGT0PJJWNB1wc03PM\" alt=\"RNN Architecture\" style=\"width: 80%;\">\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference -> Statquest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%writefile modules/LSTM_Architecture.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "class LSTM(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        mean = torch.tensor(0.0)\n",
    "        std = torch.tensor(1.0)\n",
    "        \n",
    "        self.wlr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wlr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.blr1 = nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        \n",
    "        self.wpr1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wpr2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bpr1 = nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        \n",
    "        self.wp1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wp2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bp1 = nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        \n",
    "        self.wo1 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.wo2 = nn.Parameter(torch.normal(mean=mean, std=std), requires_grad=True)\n",
    "        self.bo1 = nn.Parameter(torch.tensor(0.0),requires_grad=True)\n",
    "        \n",
    "        \n",
    "    def lstm_unit(self, input_value, long_memory, short_memory):\n",
    "        \n",
    "        long_remember_percent = torch.sigmoid((short_memory*self.wlr1)+(input_value*self.wlr2)+self.blr1)\n",
    "        \n",
    "        potential_memory_remember_percent = torch.sigmoid((short_memory*self.wpr1) + (input_value*self.wpr2) + self.bpr1)\n",
    "        \n",
    "        potential_long_term_memory = torch.tanh((short_memory*self.wp1) + (input_value*self.wp2) + self.bp1)\n",
    "        \n",
    "        updated_long_term_memory = ((long_memory*long_remember_percent) + (potential_long_term_memory*potential_memory_remember_percent))\n",
    "        \n",
    "        output_percent = torch.sigmoid((short_memory*self.wo1) + (input_value*self.wo2) + self.bo1)\n",
    "        \n",
    "        updated_short_term_memory = torch.tanh(updated_long_term_memory) * output_percent\n",
    "        \n",
    "        return ([updated_long_term_memory, updated_short_term_memory])\n",
    "    \n",
    "    \n",
    "    \n",
    "    #This LSTM Example code takes the input values of a share for 4 days and predicts the 5th day by considering all the day values. \n",
    "    #Predefined values -> First Company : [0,0.5,0.25,1] (Expected Prediction -> 0)\n",
    "    #                   Second Company : [1,0.5,0.25,1] (Expected Prediction -> 1)\n",
    "    def forward(self, input):\n",
    "        long_memory = 0\n",
    "        short_memory = 0\n",
    "    \n",
    "        for day in input:\n",
    "            long_memory, short_memory = self.lstm_unit(day, long_memory, short_memory)\n",
    "    \n",
    "        return short_memory\n",
    "    \n",
    "    \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i , label_i = batch\n",
    "        output_i = self.forward(input_i[0])\n",
    "        \n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss = loss_fn(output_i, label_i)\n",
    "        \n",
    "        self.log(\"Training Loss\", loss)\n",
    "        \n",
    "        if label_i==0:\n",
    "            self.log(\"out_0\", output_i)  #Very bruteforce way to check if we predicted for company first or second\n",
    "        else:\n",
    "            self.log(\"out_1\", output_i)\n",
    "            \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3050 Ti Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training ===>\n",
      "\n",
      "\n",
      "\n",
      "Comparing Observed and Predicted Value ==>\n",
      "\n",
      "Company A => Observed -> 0 & Predicted -> tensor(0.0888) \n",
      "\n",
      "Company B => Observed -> 0 & Predicted -> tensor(0.1018)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name         | Type | Params | Mode\n",
      "---------------------------------------------\n",
      "  | other params | n/a  | 12     | n/a \n",
      "---------------------------------------------\n",
      "12        Trainable params\n",
      "0         Non-trainable params\n",
      "12        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "0         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20000: 100%|██████████| 2/2 [00:00<00:00, 120.16it/s, v_num=0]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20001` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20000: 100%|██████████| 2/2 [00:00<00:00, 87.81it/s, v_num=0] \n",
      "After Training ===>\n",
      "\n",
      "\n",
      "\n",
      "Comparing Observed and Predicted Value ==>\n",
      "\n",
      "Company A => Observed -> 0 & Predicted -> tensor(-7.3200e-06) \n",
      "\n",
      "Company B => Observed -> 0 & Predicted -> tensor(0.9977)\n"
     ]
    }
   ],
   "source": [
    "# %%writefile modules/training.py\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from modules.LSTM_Architecture import *\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "model = LSTM()\n",
    "\n",
    "#Before Training -> \n",
    "print(\"Before Training ===>\\n\\n\\n\")\n",
    "print(\"Comparing Observed and Predicted Value ==>\\n\\nCompany A => Observed -> 0 & Predicted ->\",model(torch.tensor([0.0,0.5,0.25,1.0])).detach(),\"\\n\\nCompany B => Observed -> 0 & Predicted ->\",model(torch.tensor([1.0,0.5,0.25,1.0])).detach())\n",
    "\n",
    "\n",
    "#Training -> \n",
    "inputs = torch.tensor([[0.0,0.5,0.25,1.0],[1.0,0.5,0.25,1.0]])\n",
    "labels = torch.tensor([0.0,1.0])\n",
    "\n",
    "dataset = TensorDataset(inputs,labels)\n",
    "dataloader = DataLoader(dataset=dataset)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20001)\n",
    "\n",
    "trainer.fit(model=model, train_dataloaders=dataloader)\n",
    "print(\"After Training ===>\\n\\n\\n\")\n",
    "print(\"Comparing Observed and Predicted Value ==>\\n\\nCompany A => Observed -> 0 & Predicted ->\",model(torch.tensor([0.0,0.5,0.25,1.0])).detach(),\"\\n\\nCompany B => Observed -> 0 & Predicted ->\",model(torch.tensor([1.0,0.5,0.25,1.0])).detach())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected -> 0, 1  & Predicted -> -0.000007 , 0.9977 -> Very Accurate :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name | Type | Params | Mode \n",
      "--------------------------------------\n",
      "0 | lstm | LSTM | 16     | train\n",
      "--------------------------------------\n",
      "16        Trainable params\n",
      "0         Non-trainable params\n",
      "16        Total params\n",
      "0.000     Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Training ===>\n",
      "\n",
      "\n",
      "\n",
      "Comparing Observed and Predicted Value ==>\n",
      "\n",
      "Company A => Observed -> 0 & Predicted -> tensor([-0.1441]) \n",
      "\n",
      "Company B => Observed -> 0 & Predicted -> tensor([-0.1091])\n",
      "Epoch 1000: 100%|██████████| 2/2 [00:00<00:00, 148.31it/s, v_num=4]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=1001` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1000: 100%|██████████| 2/2 [00:00<00:00, 102.19it/s, v_num=4]\n",
      "After Training ===>\n",
      "\n",
      "\n",
      "\n",
      "Comparing Observed and Predicted Value ==>\n",
      "\n",
      "Company A => Observed -> 0 & Predicted -> tensor([2.8894e-06]) \n",
      "\n",
      "Company B => Observed -> 0 & Predicted -> tensor([0.9951])\n"
     ]
    }
   ],
   "source": [
    "#LSTM Implementation using PyTorch's Inbuilt Class -->\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class LSTMAuto(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size = 1, hidden_size = 1, batch_first = True)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        \n",
    "        input_trans = input.reshape(len(input),1)\n",
    "        \n",
    "        lstm_output , temp = self.lstm(input_trans)\n",
    "        \n",
    "        prediction = lstm_output[-1]\n",
    "        \n",
    "        return prediction\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr = 0.1)\n",
    "\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_i , label_i = batch\n",
    "        output_i = self.forward(input_i[0])\n",
    "        \n",
    "        loss_fn = torch.nn.MSELoss()\n",
    "        loss = loss_fn(output_i, label_i)\n",
    "        \n",
    "        self.log(\"Training Loss\", loss)\n",
    "        \n",
    "        if label_i==0:\n",
    "            self.log(\"out_0\", output_i)  #Very bruteforce way to check if we predicted for company first or second\n",
    "        else:\n",
    "            self.log(\"out_1\", output_i)\n",
    "            \n",
    "        return loss\n",
    "    \n",
    "    \n",
    "model2 = LSTMAuto()\n",
    "\n",
    "print(\"Before Training ===>\\n\\n\\n\")\n",
    "print(\"Comparing Observed and Predicted Value ==>\\n\\nCompany A => Observed -> 0 & Predicted ->\",model2(torch.tensor([0.0,0.5,0.25,1.0])).detach(),\"\\n\\nCompany B => Observed -> 0 & Predicted ->\",model2(torch.tensor([1.0,0.5,0.25,1.0])).detach())\n",
    "\n",
    "inputs = torch.tensor([[0.0,0.5,0.25,1.0],[1.0,0.5,0.25,1.0]])\n",
    "labels = torch.tensor([0.0,1.0])\n",
    "\n",
    "dataset = TensorDataset(inputs,labels)\n",
    "dataloader = DataLoader(dataset=dataset)\n",
    "\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=1001, log_every_n_steps=5)\n",
    "\n",
    "trainer.fit(model=model2, train_dataloaders=dataloader)\n",
    "print(\"After Training ===>\\n\\n\\n\")\n",
    "print(\"Comparing Observed and Predicted Value ==>\\n\\nCompany A => Observed -> 0 & Predicted ->\",model2(torch.tensor([0.0,0.5,0.25,1.0])).detach(),\"\\n\\nCompany B => Observed -> 0 & Predicted ->\",model2(torch.tensor([1.0,0.5,0.25,1.0])).detach())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great accuracy in lesser epochs as the LSTM model weights in the inbuilt library are more optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tensorboard --logdir lightning_logs --port 6008"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
