{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Basic Implementation of spaCy & NLTK**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spaCy -> Newer Library, Already comes tuned with spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "NLTK  -> Older Library, Can be heavily customised but hard to operate with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I like black cats.\n",
      "Dr. Ramesh likes brown dogs.\n",
      "There are a lot of people that I know of that have multiple pets.\n",
      "For example Koompilala, Dhunnibaba etc. because Having pets is cute.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"I like black cats. Dr. Ramesh likes brown dogs. There are a lot of people that I know of that have multiple pets. For example Koompilala, Dhunnibaba etc. because Having pets is cute.\")\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n",
    "    \n",
    "# for sentence in doc.sents:          \n",
    "#     for word in sentence:                   #This prints all words one by one.\n",
    "#         print(word)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I like black cats.',\n",
       " 'Dr. Ramesh likes brown dogs.',\n",
       " 'There are a lot of people that I know of that have multiple pets.',\n",
       " 'For example Koompilala, Dhunnibaba etc.',\n",
       " 'because Having pets is cute.']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "sent_tokenize(\"I like black cats. Dr. Ramesh likes brown dogs. There are a lot of people that I know of that have multiple pets. For example Koompilala, Dhunnibaba etc. because Having pets is cute.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tokenization in spaCY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let\n",
      "'s\n",
      "go\n",
      "to\n",
      "N.Y\n",
      "!\n"
     ]
    }
   ],
   "source": [
    "#Word Tokenization -> \n",
    "import spacy\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "doc = nlp(\"Let's go to N.Y!\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(spacy.lang.en.English,\n",
       " spacy.tokens.doc.Doc,\n",
       " spacy.tokens.token.Token,\n",
       " spacy.tokens.span.Span)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "span = doc[2:4]\n",
    "type(nlp) , type(doc) , type(token) , type(span)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True, False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp (\"I have 2 two ₹ coins in my pocket.\")\n",
    "\n",
    "doc[2].like_num , doc[3].like_num , doc[4].is_currency, doc[5].is_digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['john.smith@email.com', 'emily.j@university.edu', 'mchen98@student.org', 'srodriguez@school.net', 'akim2002@college.com']\n"
     ]
    }
   ],
   "source": [
    "student_details = \"\"\"\n",
    "John Smith, 19, john.smith@email.com, 2005-03-15\n",
    "Emily Johnson, 21, emily.j@university.edu, 2003-07-22\n",
    "Michael Chen, 20, mchen98@student.org, 2004-11-30\n",
    "Sophia Rodriguez, 18, srodriguez@school.net, 2006-01-08\n",
    "Alexander Kim, 22, akim2002@college.com, 2002-09-04\n",
    "\"\"\"\n",
    "doc = nlp(student_details)\n",
    "email_array =[]\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        email_array.append(token.text)\n",
    "        \n",
    "        \n",
    "print(email_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['sentencizer']\n"
     ]
    }
   ],
   "source": [
    "#This is how we add components to pipelines -> \n",
    "print(nlp.pipe_names)\n",
    "\n",
    "nlp.add_pipe('sentencizer')\n",
    "\n",
    "print(nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.data.gov/\n",
      "http://www.science\n",
      "http://data.gov.uk/.\n",
      "http://www3.norc.org/gss+website/\n",
      "http://www.europeansocialsurvey.org/.\n"
     ]
    }
   ],
   "source": [
    "text='''\n",
    "Look for data to help you address the question. Governments are good\n",
    "sources because data from public research is often freely available. Good\n",
    "places to start include http://www.data.gov/, and http://www.science.\n",
    "gov/, and in the United Kingdom, http://data.gov.uk/.\n",
    "Two of my favorite data sets are the General Social Survey at http://www3.norc.org/gss+website/, \n",
    "and the European Social Survey at http://www.europeansocialsurvey.org/.\n",
    "'''\n",
    "\n",
    "for url in nlp(text): \n",
    "    if url.like_url:\n",
    "        print(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two $\n",
      "500 €\n"
     ]
    }
   ],
   "source": [
    "transactions = \"Tony gave two $ to Peter, Bruce gave 500 € to Steve\"\n",
    "doc = nlp(transactions)\n",
    "\n",
    "for token in doc:\n",
    "    if token.like_num and doc[token.i+1].is_currency:\n",
    "        print(token.text , doc[token.i+1].text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Language Processing Pipeline in spaCy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "print(nlp.pipe_names)\n",
    "\n",
    "#Already trained NLP Pipeline -> \n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "print(nlp.pipe_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yesterday       yesterday       NOUN \n",
      ",               ,               PUNCT\n",
      "42              42              NUM  \n",
      "enthusiastic    enthusiastic    ADJ  \n",
      "students        student         NOUN \n",
      "from            from            ADP  \n",
      "our             our             PRON \n",
      "local           local           ADJ  \n",
      "high            high            ADJ  \n",
      "school          school          NOUN \n",
      "eagerly         eagerly         ADV  \n",
      "participated    participate     VERB \n",
      "in              in              ADP  \n",
      "the             the             DET  \n",
      "15th            15th            ADJ  \n",
      "annual          annual          ADJ  \n",
      "science         science         NOUN \n",
      "fair            fair            NOUN \n",
      ",               ,               PUNCT\n",
      "where           where           SCONJ\n",
      "they            they            PRON \n",
      "showcased       showcase        VERB \n",
      "7               7               NUM  \n",
      "innovative      innovative      ADJ  \n",
      "projects        project         NOUN \n",
      ".               .               PUNCT\n"
     ]
    }
   ],
   "source": [
    "complex_sentence = \"Yesterday, 42 enthusiastic students from our local high school eagerly participated in the 15th annual science fair, where they showcased 7 innovative projects.\"\n",
    "doc = nlp(complex_sentence)\n",
    "\n",
    "for token in doc:\n",
    "    \n",
    "    print(f\"{token.text:<15} {token.lemma_:<15} {token.pos_:<5}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real Madrid FC            ORG             Companies, agencies, institutions, etc.\n",
      "last 5                    DATE            Absolute or relative dates or periods\n",
      "3 million $               MONEY           Monetary values, including unit\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Real Madrid FC\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " has scored many goals in \n",
       "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    last 5\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
       "</mark>\n",
       " games, Increasing their valuation by \n",
       "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    3 million $\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">MONEY</span>\n",
       "</mark>\n",
       ".</div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "doc = nlp(\"Real Madrid FC has scored many goals in last 5 games, Increasing their valuation by 3 million $.\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<25} {ent.label_:<15} {spacy.explain(ent.label_)}\")\n",
    "    \n",
    "    \n",
    "from spacy import displacy\n",
    "\n",
    "displacy.render(doc, style =\"ent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ner']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Code to only create a pipeline with ner rather than all the entities --> \n",
    "\n",
    "source_nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "nlp = spacy.blank('en')\n",
    "\n",
    "nlp.add_pipe('ner', source=source_nlp)\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Stemming and Lemmatization ->** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stemming** -> Getting the base word out of a complex word. It just uses simple rules like removing \"able\", \"ing\" etc. Examples -> \n",
    "\n",
    "- Talking -> Talk\n",
    "- Adjustable -> Adjust\n",
    "\n",
    "\n",
    "**Lemmatization** -> Getting the base word by using linguistic knowledge and not just fixed rules. Base word is also called lemma. Examples -> \n",
    "- Ate -> Eat\n",
    "- Ability -> Able"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running         run\n",
      "jumps           jump\n",
      "easily          easili\n",
      "dogs            dog\n",
      "cats            cat\n",
      "better          better\n",
      "friendliness    friendli\n",
      "jumping         jump\n",
      "leaves          leav\n",
      "babies          babi\n",
      "ability         abil\n",
      "organization    organ\n",
      "programmer      programm\n"
     ]
    }
   ],
   "source": [
    "from nltk import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "words = [\n",
    "    \"running\", \"jumps\", \"easily\", \"dogs\", \"cats\", \"better\", \"friendliness\", \"jumping\", \"leaves\", \"babies\", \"ability\", \"organization\", \"programmer\"\n",
    "]\n",
    "\n",
    "for word in words : \n",
    "    print(f\"{word:<15} {stemmer.stem(word)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stemming doesn't use language comphrehension and thus its results are not the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running         running\n",
      "jumps           jump\n",
      "easily          easily\n",
      "dogs            dog\n",
      "cats            cat\n",
      "better          well\n",
      "friendliness    friendliness\n",
      "jumping         jump\n",
      "leaves          leave\n",
      "babies          baby\n",
      "ability         ability\n",
      "organization    organization\n",
      "programmer      programmer\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "doc = nlp(\"running jumps easily dogs cats better friendliness jumping leaves babies ability organization programmer\")\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<15} {token.lemma_}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Part Of Speech POS Tagging ->**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The          DET        determiner      DT         determiner\n",
      "curious      ADJ        adjective       JJ         adjective (English), other noun-modifier (Chinese)\n",
      "cat          NOUN       noun            NN         noun, singular or mass\n",
      "quickly      ADV        adverb          RB         adverb\n",
      "chased       VERB       verb            VBD        verb, past tense\n",
      "five         NUM        numeral         CD         cardinal number\n",
      "red          ADJ        adjective       JJ         adjective (English), other noun-modifier (Chinese)\n",
      "butterflies  NOUN       noun            NNS        noun, plural\n",
      "across       ADP        adposition      IN         conjunction, subordinating or preposition\n",
      "our          PRON       pronoun         PRP$       pronoun, possessive\n",
      "sunny        ADJ        adjective       JJ         adjective (English), other noun-modifier (Chinese)\n",
      "garden       NOUN       noun            NN         noun, singular or mass\n",
      "yesterday    NOUN       noun            NN         noun, singular or mass\n",
      ".            PUNCT      punctuation     .          punctuation mark, sentence closer\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "short_sentence = \"The curious cat quickly chased five red butterflies across our sunny garden yesterday.\"\n",
    "\n",
    "doc = nlp(short_sentence)\n",
    "\n",
    "for token in doc:\n",
    "    print(f\"{token.text:<12} {token.pos_:<10} {spacy.explain(token.pos_):<15} {token.tag_:<10} {spacy.explain(token.tag_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Microsoft,\n",
       " Corp.,\n",
       " today,\n",
       " announced,\n",
       " the,\n",
       " following,\n",
       " results,\n",
       " for,\n",
       " the,\n",
       " quarter]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "earnings_text=\"\"\"Microsoft Corp. today announced the following results for the quarter ended December 31, 2021, as compared to the corresponding period of last fiscal year:\n",
    "\n",
    "·         Revenue was $51.7 billion and increased 20%\n",
    "·         Operating income was $22.2 billion and increased 24%\n",
    "·         Net income was $18.8 billion and increased 21%\n",
    "·         Diluted earnings per share was $2.48 and increased 22%\n",
    "“Digital technology is the most malleable resource at the world’s disposal to overcome constraints and reimagine everyday work and life,” said Satya Nadella, chairman and chief executive officer of Microsoft. “As tech as a percentage of global GDP continues to increase, we are innovating and investing across diverse and growing markets, with a common underlying technology stack and an operating model that reinforces a common strategy, culture, and sense of purpose.”\n",
    "“Solid commercial execution, represented by strong bookings growth driven by long-term Azure commitments, increased Microsoft Cloud revenue to $22.1 billion, up 32% year over year” said Amy Hood, executive vice president and chief financial officer of Microsoft.\"\"\"\n",
    "\n",
    "doc = nlp(earnings_text)\n",
    "\n",
    "filtered_tokens = []\n",
    "\n",
    "for token in doc:\n",
    "    if token.pos_ not in [\"SPACE\", \"PUNCT\", \"X\"]:\n",
    "        filtered_tokens.append(token)\n",
    "        \n",
    "filtered_tokens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROPN | 15\n",
      "NOUN | 45\n",
      "VERB | 23\n",
      "DET | 9\n",
      "ADP | 16\n",
      "NUM | 16\n",
      "PUNCT | 27\n",
      "SCONJ | 1\n",
      "ADJ | 20\n",
      "SPACE | 10\n",
      "AUX | 6\n",
      "SYM | 5\n",
      "CCONJ | 12\n",
      "ADV | 3\n",
      "PART | 3\n",
      "PRON | 2\n"
     ]
    }
   ],
   "source": [
    "count = doc.count_by(spacy.attrs.POS)\n",
    "for k,v in count.items():\n",
    "    print(doc.vocab[k].text, \"|\",v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Named Entity Recognition (NER) ->**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc.           ORG             Companies, agencies, institutions, etc.\n",
      "New York City        GPE             Countries, cities, states\n",
      "next month           DATE            Absolute or relative dates or periods\n",
      "Tim Cook             PERSON          People, including fictional\n",
      "San Francisco        GPE             Countries, cities, states\n",
      "last week            DATE            Absolute or relative dates or periods\n"
     ]
    }
   ],
   "source": [
    "text = \"Apple Inc. is planning to open a new store in New York City next month. CEO Tim Cook announced the plan during a conference in San Francisco last week. Twitter is the most popular social media platform in the world.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<20} {ent.label_:<15} {spacy.explain(ent.label_):<20}\")\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple Inc.           ORG             Companies, agencies, institutions, etc.\n",
      "New York City        GPE             Countries, cities, states\n",
      "next month           DATE            Absolute or relative dates or periods\n",
      "Tim Cook             PERSON          People, including fictional\n",
      "San Francisco        GPE             Countries, cities, states\n",
      "last week            DATE            Absolute or relative dates or periods\n",
      "Twitter              ORG             Companies, agencies, institutions, etc.\n"
     ]
    }
   ],
   "source": [
    "#As Twitter is not included in spacy, we can add it manually.\n",
    "\n",
    "from spacy.tokens import Span\n",
    "\n",
    "s1 = Span(doc,31,32,label=\"ORG\")\n",
    "new_ents = list(doc.ents)\n",
    "new_ents.append(s1)\n",
    "doc.ents = new_ents\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.text:<20} {ent.label_:<15} {spacy.explain(ent.label_):<20}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
